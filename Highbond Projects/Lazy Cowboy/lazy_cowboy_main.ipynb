{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robot task scope\n",
    "V_HB_PROJECT_STATUSES: list     = [\"draft\",\"proposed\",\"active\"] # use ... = [] if projects with all statuses are in scope\n",
    "V_HB_PROJECT_TYPE_ID:  list     = [] # use ... = [] if projects with all project types are in scope\n",
    "V_HB_PROJECT_TAGS: str          = \"risk and control assessment\" # one tag allowed\n",
    "V_EXCLUSION_STATUS_LABELS: list = [\"Rejected\"] # multiple statuses accepted\n",
    "\n",
    "\n",
    "# Environment variables of Highbond setup\n",
    "V_HB_ORG_ID: str        = \"14016\"\n",
    "V_HB_ORG_SUBDOMAIN: str = \"tr\"\n",
    "V_HB_ORG_REGION: str    = \"us\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas, requests, json\n",
    "\n",
    "pandas.options.display.max_rows = 10\n",
    "pandas.options.display.max_columns = None\n",
    "pandas.options.display.max_colwidth = 50\n",
    "\n",
    "# Debugging mode on/off\n",
    "debug = True\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Checking user input variables. If they're not provided, raise exception and terminate script.\n",
    "if len(hcl.secret[\"v_hb_token\"].unmask()) == 0:\n",
    "    raise KeyError(\"HighBond token not provided.\")\n",
    "\"\"\"\n",
    "\n",
    "# Highbond url\n",
    "hb_org_base_url: str = f\"https://apis-{V_HB_ORG_REGION.strip()}.highbond.com/v1/orgs/{V_HB_ORG_ID.strip()}\"\n",
    "\n",
    "# Request headers for Highbond\n",
    "hb_request_headers: dict = {\n",
    "    \"Authorization\": \"Bearer ee93272f8f8e718d9e7ad027f2f13e0eb345c938709d9ac759821b152ee709cc\",\n",
    "#    \"Authorization\": \"Bearer {}\".format(hcl.secret[\"v_hb_token\"].unmask()),\n",
    "    \"Content-Type\": \"application/vnd.api+json\",\n",
    "    \"Accept-encoding\": \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE HELPER FUNCTIONS\n",
    "\n",
    "##################################################################\n",
    "# Function 1 - Helper function to grab all Highbond resources (pagination)\n",
    "def highbond_api_get_all(resource_url_body: str) -> list:\n",
    "    \"\"\"\n",
    "    Importing Highbond data and creating a list (taking care of pagination if necessary)\n",
    "    Args:\n",
    "        resource_url_body: URL body of the request\n",
    "    Returns:\n",
    "        List of resources\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = requests.request(\"GET\", hb_org_base_url + resource_url_body, headers=hb_request_headers)\n",
    "        response.raise_for_status()\n",
    "        if debug:\n",
    "            print(\"GET response: \", response, \"\\n\")\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        raise requests.exceptions.RequestException(err)\n",
    "    \n",
    "    # Grab the response as a JSON\n",
    "    response_json = response.json()\n",
    "    list_of_result_dicts = response_json[\"data\"]\n",
    "\n",
    "    # If endpoint is paginated, let's do the job. If not, return the original dictionary\n",
    "    if \"links\" in response_json:\n",
    "        while response.status_code == 200:\n",
    "            if response_json['links']['next'] and len(response_json['links']['next']) > 0:\n",
    "                next_url = response_json['links']['next']\n",
    "                \n",
    "                try:\n",
    "                    response = requests.request(\"GET\", hb_org_base_url + next_url, headers=hb_request_headers)\n",
    "                    response.raise_for_status()\n",
    "                    if debug:\n",
    "                        print(\"GET loop response: \", response, \"\\n\")\n",
    "                except requests.exceptions.RequestException as err:\n",
    "                    raise requests.exceptions.RequestException(err)\n",
    "            \n",
    "                response_json = response.json()\n",
    "                list_of_result_dicts.extend(response_json[\"data\"])\n",
    "            \n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    return list_of_result_dicts\n",
    "\n",
    "\n",
    "\n",
    "##################################################################\n",
    "# Function 2 - Helper function to flatten all custom attributes\n",
    "def flatten_custom_attributes(custom_attribute_field_value) -> dict:\n",
    "    \"\"\"\n",
    "    Flattening the custom attributes in the dataframe\n",
    "    Args:\n",
    "        custom_attribute_field_value: custom attributes\n",
    "    Returns:\n",
    "        Dictionary with flattened custom attributes \n",
    "    \"\"\"\n",
    "\n",
    "    custom_attribute_dict = {} # Initialize empty dictionary\n",
    "    for attribute in custom_attribute_field_value:           # There can be multiple custom attributes, so we need to loop through each one to parse it\n",
    "        if isinstance(attribute[\"value\"], list) and len(attribute[\"value\"]) == 1:   # If the custom attribute value is a list itself and only having one value, \"de-listify it\"\n",
    "            attribute[\"value\"] = attribute[\"value\"][0] # De listifies the value list\n",
    "        elif isinstance(attribute[\"value\"], list) and not attribute[\"value\"]:\n",
    "            attribute[\"value\"] = None # De listifies the value list\n",
    "        custom_attribute_dict[attribute[\"term\"]] = attribute[\"value\"] # Create the dictionary tuple with the custom attribute term and value\n",
    "    return custom_attribute_dict # Return the completed dictionary\n",
    "\n",
    "\n",
    "\n",
    "##################################################################\n",
    "# Function 3 - GET Results Tables Data\n",
    "def get_from_hb_results(results_table_id: str, include_metadata: bool = False, display_names: bool = False) -> pandas.DataFrame:\n",
    "    \"\"\"\n",
    "    Importing current Results Table in a formatted way\n",
    "    Args:\n",
    "        results_table_id: ID of the Highbond Results Table\n",
    "        include_metadata: Flag for whether or not to include metadata fields (e.g. priority, status, publisher, publish_date, etc.)\n",
    "        display_names: Flag for whether to convert the column names to their display names for easier readability\n",
    "    Returns:\n",
    "        Current Results table in a pandas dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # Submit the request and grab the response, and convert it to JSON\n",
    "    try:\n",
    "        request_endpoint = \"/tables/\" + results_table_id + \"/records/\"\n",
    "        request_response = requests.request(\"GET\", hb_org_base_url + request_endpoint, headers=hb_request_headers)\n",
    "        request_response.raise_for_status()\n",
    "        if debug:\n",
    "            print(\"GET RESULTS TABLE response: \", request_response, \"\\n\")\n",
    "    except requests.exceptions.RequestException as get_err:\n",
    "        raise requests.exceptions.RequestException(get_err)\n",
    "\n",
    "    # Grab the response as a JSON\n",
    "    request_json = request_response.json()\n",
    "    Results_Records_df = pandas.json_normalize(request_json[\"data\"]) # Convert the response JSON to a dataframe -- we grab data from the \"data\" element\n",
    "    \n",
    "    # If no data is in the Results Table, return\n",
    "    if Results_Records_df.empty:\n",
    "        return Results_Records_df\n",
    "\n",
    "    if debug and not include_metadata:\n",
    "        print(\"Before: \" + Results_Records_df.columns)    \n",
    "\n",
    "    if not include_metadata:\n",
    "        for column_name in Results_Records_df.columns:\n",
    "            if column_name.startswith('metadata.') or column_name.startswith('extras.'): \n",
    "                del Results_Records_df[column_name]\n",
    "\n",
    "    if debug and not include_metadata:\n",
    "        print(\"After: \" + Results_Records_df.columns)    \n",
    "\n",
    "    # Grab the records from the response and rename the columns\n",
    "    if display_names:\n",
    "        # Grab the columns metadata into a dataframe\n",
    "        Results_Columns_df = pandas.json_normalize(request_json[\"columns\"])\n",
    "        # Create a dictionary from the display name and field name\n",
    "        Results_Column_Mapping_dict = pandas.Series(Results_Columns_df.display_name.values,index=Results_Columns_df.field_name).to_dict()\n",
    "        # Renaming the fields with display names\n",
    "        Results_Records_df.rename(columns = Results_Column_Mapping_dict, inplace = True)\n",
    "\n",
    "    # Converting field types and creating final DataFrame to return\n",
    "    Results_Records_df = Results_Records_df.convert_dtypes()\n",
    "\n",
    "\n",
    "    return Results_Records_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN LOGIC 1\n",
    "# PREPARING THE PROJECTS IN SCOPE DATA\n",
    "\n",
    "########################################\n",
    "# Fetching all projects from Highbond and filter for those which are in scope\n",
    "hb_projects_list = highbond_api_get_all(\"/projects/\")\n",
    "\n",
    "# Filtering for the in-scope projects \n",
    "if V_HB_PROJECT_STATUSES and V_HB_PROJECT_TYPE_ID:\n",
    "    hb_projects_list_filtered = [project for project in hb_projects_list if project['attributes']['state'] == \"active\" and V_HB_PROJECT_TAGS in project['attributes']['tag_list'] and project['attributes']['status'] in V_HB_PROJECT_STATUSES and project['relationships']['project_type']['data']['id'] in V_HB_PROJECT_TYPE_ID]\n",
    "elif V_HB_PROJECT_STATUSES:\n",
    "    hb_projects_list_filtered = [project for project in hb_projects_list if project['attributes']['state'] == \"active\" and V_HB_PROJECT_TAGS in project['attributes']['tag_list'] and project['attributes']['status'] in V_HB_PROJECT_STATUSES]\n",
    "elif V_HB_PROJECT_TYPE_ID:\n",
    "    hb_projects_list_filtered = [project for project in hb_projects_list if project['attributes']['state'] == \"active\" and V_HB_PROJECT_TAGS in project['attributes']['tag_list'] and project['relationships']['project_type']['data']['id'] in V_HB_PROJECT_TYPE_ID]\n",
    "else:\n",
    "    hb_projects_list_filtered = [project for project in hb_projects_list if project['attributes']['state'] == \"active\" and V_HB_PROJECT_TAGS in project['attributes']['tag_list']]\n",
    "\n",
    "try:\n",
    "    print(\"First project ID:\" , hb_projects_list_filtered[0][\"id\"])\n",
    "except IndexError as err:\n",
    "    print(\"Warning: No project found for the in-scope project statuses, project types and project tags. Task run terminated.\")\n",
    "    raise IndexError(err)\n",
    "except:\n",
    "    raise Exception(\"Unkonown error in getting the projects for the in-scope project statuses, project types and project tags. Task run terminated.\")\n",
    "\n",
    "# Creating DataFrame from the in-scope projects\n",
    "hb_projects_df = pandas.json_normalize(hb_projects_list_filtered)\n",
    "hb_projects_df = hb_projects_df[[\"id\",\"attributes.name\",\"attributes.number_of_testing_rounds\",\"relationships.project_type.data.id\"]]\n",
    "hb_projects_df\n",
    "\n",
    "# Getting the project type info\n",
    "hb_project_types_list = []\n",
    "for project in hb_projects_list_filtered:\n",
    "    project_type_id = project[\"relationships\"][\"project_type\"][\"data\"][\"id\"]\n",
    "    hb_project_types_list_current = highbond_api_get_all(\"/project_types/\" + project_type_id + \"?fields[project_types]=all\")\n",
    "    hb_project_types_list.append(hb_project_types_list_current)\n",
    "\n",
    "# Creating DataFrame from the in-scope project types\n",
    "hb_project_types_df = pandas.json_normalize(hb_project_types_list)\n",
    "hb_project_types_df\n",
    "\n",
    "# Attaching the project type information to the projects dataframe\n",
    "hb_projects_pt_df = pandas.merge(hb_projects_df, hb_project_types_df[[\"id\",\"attributes.certification_terms.term_for_certifications\",\"attributes.risk_terms.term_for_risk_impact\",\"attributes.risk_terms.term_for_risk_likelihood\",\"attributes.walkthrough_terms.term_for_walkthrough\",\"attributes.walkthrough_terms.term_for_walkthrough_walkthrough\",\"attributes.walkthrough_terms.control_verified_values_true\",\"attributes.walkthrough_terms.control_verified_values_false\",\"attributes.control_test_terms.term_for_control_test_testing\",\"attributes.control_test_terms.term_for_control_test_test_results\",\"attributes.control_test_terms.conclusion_values_true\",\"attributes.control_test_terms.conclusion_values_false\"]], how=\"inner\", left_on=\"relationships.project_type.data.id\", right_on=\"id\", suffixes=(\"_project\", \"_project_type\")).drop(\"id_project_type\", axis=1)\n",
    "hb_projects_pt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN LOGIC 2\n",
    "# PREPARING THE TABLE WITH ALL PROJECTS AND RELATED COLLECTIONS/ANALYSES/TABLES INFO \n",
    "\n",
    "########################################\n",
    "# Fetching all Results Tables from Highbond and filter for those which are in scope\n",
    "\n",
    "# COLLECTIONS\n",
    "# Fetching all Collections and filtering for the in-scope colletions (mathcing projects with relating collections)\n",
    "hb_collections_list = highbond_api_get_all(\"/collections/\")\n",
    "hb_collections_list_filtered = [collection for collection in hb_collections_list if collection[\"attributes\"][\"name\"] in [project[\"attributes\"][\"name\"] for project in hb_projects_list_filtered]]\n",
    "hb_collections_list_filtered\n",
    "\n",
    "# Creating DataFrame from the Collections\n",
    "hb_collections_df = pandas.json_normalize(hb_collections_list_filtered)\n",
    "hb_collections_df\n",
    "\n",
    "# Join Collection info back to Projects DataFrame\n",
    "hb_projects_pt_c_df = pandas.merge(hb_projects_pt_df, hb_collections_df[[\"id\",\"attributes.name\"]], how=\"inner\", left_on=\"attributes.name\", right_on=\"attributes.name\")\n",
    "hb_projects_pt_c_df.rename(columns={\"id\": \"id_collection\"}, inplace=True)\n",
    "hb_projects_pt_c_df\n",
    "\n",
    "\n",
    "# ANALYSIES\n",
    "# Fetching all Analyses and filtering for the in-scope Analyses\n",
    "hb_analyses_list = []\n",
    "for collection in hb_collections_list_filtered:\n",
    "    hb_analyses_list_current = highbond_api_get_all(\"/collections/\" + collection[\"id\"] + \"/analyses/\")\n",
    "    hb_analyses_list.extend(hb_analyses_list_current)\n",
    "\n",
    "# Creating DataFrame from the Analyses\n",
    "hb_analyses_df = pandas.json_normalize(hb_analyses_list)\n",
    "hb_analyses_df\n",
    "\n",
    "# Join Analyses info back to Projects DataFrame\n",
    "hb_projects_pt_c_a_df = pandas.merge(hb_projects_pt_c_df, hb_analyses_df[[\"id\",\"attributes.name\"]], how=\"inner\", left_on=\"attributes.certification_terms.term_for_certifications\", right_on=\"attributes.name\", suffixes=(\"_project\",\"\")).drop(\"attributes.name\", axis=1)\n",
    "hb_projects_pt_c_a_df.rename(columns={\"id\": \"id_analyses\"}, inplace=True)\n",
    "hb_projects_pt_c_a_df\n",
    "\n",
    "\n",
    "# TABLES\n",
    "# Fetching all Tables and filtering for the in-scope Tables\n",
    "hb_tables_list = []\n",
    "for analyses in hb_analyses_list:\n",
    "    hb_tables_list_current = highbond_api_get_all(\"/analyses/\" + analyses[\"id\"] + \"/tables/\")\n",
    "    hb_tables_list.extend(hb_tables_list_current)\n",
    "\n",
    "# Creating DataFrame from the Tables\n",
    "hb_tables_df = pandas.json_normalize(hb_tables_list)\n",
    "hb_tables_df = hb_tables_df[hb_tables_df[\"attributes.name\"] == \"Responses\"]\n",
    "hb_tables_df\n",
    "\n",
    "# Join Table info back to Projects DataFrame\n",
    "hb_projects_pt_c_a_t_df = pandas.merge(hb_projects_pt_c_a_df, hb_tables_df[[\"id\",\"relationships.analysis.data.id\"]], how=\"inner\", left_on=\"id_analyses\", right_on=\"relationships.analysis.data.id\", suffixes=(\"_project\",\"\")).drop(\"relationships.analysis.data.id\", axis=1)\n",
    "hb_projects_pt_c_a_t_df.rename(columns={\"id\": \"id_table\"}, inplace=True)\n",
    "\n",
    "# Creating the final prepared DataFrame\n",
    "hb_projects_all = hb_projects_pt_c_a_t_df.copy()\n",
    "hb_projects_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN LOGIC 3\n",
    "# LOOPING THROUGH THE PROJECTS DATAFRAME AND PERFORM THE RELEVANT TASKS FOR EACH ROW (=ASSESSMENT)\n",
    "\n",
    "########################################\n",
    "# Main use case logic implemented here\n",
    "\n",
    "# Formatting the exclusion labels list\n",
    "V_EXCLUSION_STATUS_LABELS_stripped = [label.upper().strip() for label in V_EXCLUSION_STATUS_LABELS]\n",
    "\n",
    "# Performing tasks line by line in each Results Table\n",
    "hb_projects_all.reset_index(inplace=True)\n",
    "for index, hb_results_table in hb_projects_all.iterrows():\n",
    "    risk_scoring_factor_1 = hb_results_table.loc[\"attributes.risk_terms.term_for_risk_impact\"]\n",
    "    risk_scoring_factor_2 = hb_results_table.loc[\"attributes.risk_terms.term_for_risk_likelihood\"]\n",
    "    control_test_de_concl = hb_results_table.loc[\"attributes.walkthrough_terms.term_for_walkthrough\"]\n",
    "    control_test_de_concl_t = hb_results_table.loc[\"attributes.walkthrough_terms.control_verified_values_true\"]\n",
    "    control_test_de_concl_f = hb_results_table.loc[\"attributes.walkthrough_terms.control_verified_values_false\"]\n",
    "    control_test_de_desc = hb_results_table.loc[\"attributes.walkthrough_terms.term_for_walkthrough_walkthrough\"]\n",
    "    control_test_oe_concl = hb_results_table.loc[\"attributes.control_test_terms.term_for_control_test_testing\"]\n",
    "    control_test_oe_concl_t = hb_results_table.loc[\"attributes.control_test_terms.conclusion_values_true\"]\n",
    "    control_test_oe_concl_f = hb_results_table.loc[\"attributes.control_test_terms.conclusion_values_false\"]\n",
    "    control_test_oe_desc = hb_results_table.loc[\"attributes.control_test_terms.term_for_control_test_test_results\"]\n",
    "    # Getting the Results Tables one by one\n",
    "    hb_results_table_df = get_from_hb_results(str(hb_results_table.loc[\"id_table\"]), True, True)\n",
    "    \n",
    "    # Checking if the returned Results Table contains any data\n",
    "    if hb_results_table_df.empty:\n",
    "        if debug:\n",
    "            print(\"Results Table is empty for:\", hb_results_table.loc[\"id_table\"])\n",
    "        print(f\"\\nPROCESSING RESULTS TABLE RECORDS TASK COMPLETED FOR \" + str(hb_results_table.loc[\"id_table\"]) + \". Results Table empty. Nothing was processed.\\n\\n\")\n",
    "        continue\n",
    "    else:\n",
    "        # Looping through the Results Table line by line and perform the required actions\n",
    "        hb_results_table_df.reset_index(inplace=True)\n",
    "        hb_results_table_df.sort_values(by=[\"Updated\"], inplace=True)\n",
    "        record_counter = 0\n",
    "        for index, hb_results_table_line in hb_results_table_df.iterrows():\n",
    "\n",
    "            # **** RISK ****\n",
    "            if hb_results_table_line.loc[\"Status\"].upper().strip() not in V_EXCLUSION_STATUS_LABELS_stripped and hb_results_table_line.loc[\"Type\"].upper().strip() == \"RISK\" and risk_scoring_factor_1 in hb_results_table_line.index and risk_scoring_factor_2 in hb_results_table_line.index:\n",
    "                \n",
    "                if debug:\n",
    "                    print(hb_results_table_line.loc[\"Type\"].upper(), hb_results_table_line.loc[\"Object ID\"], hb_results_table_line.loc[\"Title\"])\n",
    "                \n",
    "                if pandas.notna(hb_results_table_line[risk_scoring_factor_1]) and pandas.notna(hb_results_table_line[risk_scoring_factor_2]):\n",
    "                    # Getting the relevant risk for update/patch\n",
    "                    try:\n",
    "                        risk_get_response = requests.request(\"GET\", str(hb_org_base_url) + \"/risks/\" + str(hb_results_table_line.loc[\"Object ID\"]), headers=hb_request_headers)\n",
    "                        risk_get_response.raise_for_status()\n",
    "                        if debug:\n",
    "                            print(\"GET response: \", risk_get_response, \"\\n\")\n",
    "                    except requests.exceptions.RequestException as risk_get_err:\n",
    "                        raise requests.exceptions.RequestException(risk_get_err)\n",
    "                    # Grab the response as a JSON\n",
    "                    risk_get_response_json = risk_get_response.json()\n",
    "                    if debug:\n",
    "                        print(\"Before state of risk:\\n\", risk_get_response_json)\n",
    "                    # Patch payload for risk scoring factors update \n",
    "                    risk_get_response_json[\"data\"][\"attributes\"][\"impact\"] = hb_results_table_line[risk_scoring_factor_1]\n",
    "                    risk_get_response_json[\"data\"][\"attributes\"][\"likelihood\"] = hb_results_table_line[risk_scoring_factor_2]\n",
    "                    if debug:\n",
    "                        print(\"After state of risk:\\n\", risk_get_response_json)\n",
    "\n",
    "                    # Patching/updating the relevant risk\n",
    "                    try:\n",
    "                        risk_patch_response = requests.request(\"PATCH\", str(hb_org_base_url) + \"/risks/\" + str(hb_results_table_line.loc[\"Object ID\"]), data=json.dumps(risk_get_response_json), headers=hb_request_headers)\n",
    "                        risk_patch_response.raise_for_status()\n",
    "                    except requests.exceptions.RequestException as risk_patch_err:\n",
    "                        raise requests.exceptions.RequestException(risk_patch_err)\n",
    "                    if debug:\n",
    "                        print(\"PATCH response: \", risk_patch_response, \"\\n\")\n",
    "                    \n",
    "                    record_counter += 1\n",
    "                    print(\"\\nGET RELEVANT RISK RECORDS AND UPDATE THEIR RISK SCORING FACTORS TASK SUCCESSFULLY RAN FOR \" + str(hb_results_table_line.loc[\"Object ID\"]), \"\\n\\n\")\n",
    "\n",
    "\n",
    "            # **** CONTROL ****\n",
    "            elif hb_results_table_line.loc[\"Status\"].upper().strip() not in V_EXCLUSION_STATUS_LABELS_stripped and hb_results_table_line.loc[\"Type\"].upper().strip() == \"CONTROL\" and (control_test_de_concl in hb_results_table_line.index and control_test_de_desc in hb_results_table_line.index or control_test_oe_concl in hb_results_table_line.index and control_test_oe_desc in hb_results_table_line.index):\n",
    "\n",
    "                if debug:\n",
    "                    print(hb_results_table_line.loc[\"Type\"].upper(), hb_results_table_line.loc[\"Object ID\"], hb_results_table_line.loc[\"Title\"])\n",
    "                \n",
    "                # Getting the relevant control to fetch the DE and OE test IDs\n",
    "                try:\n",
    "                    control_get_response = requests.request(\"GET\", str(hb_org_base_url) + \"/controls/\" + str(hb_results_table_line.loc[\"Object ID\"]) + \"?fields[controls]=walkthrough,control_tests\", headers=hb_request_headers)\n",
    "                    control_get_response.raise_for_status()\n",
    "                except requests.exceptions.RequestException as control_get_err:\n",
    "                    raise requests.exceptions.RequestException(control_get_err)\n",
    "                # Grab the response as a JSON\n",
    "                control_get_response_json = control_get_response.json()\n",
    "                control_test_de_id = control_get_response_json[\"data\"][\"relationships\"][\"walkthrough\"][\"data\"][\"id\"]\n",
    "                control_test_oe_id = control_get_response_json[\"data\"][\"relationships\"][\"control_tests\"][\"data\"][0][\"id\"]\n",
    "\n",
    "\n",
    "                # **** CONTROL DE + OE ****\n",
    "                if pandas.notna(hb_results_table_line[control_test_de_concl]) and pandas.notna(hb_results_table_line[control_test_de_desc]) and pandas.notna(hb_results_table_line[control_test_oe_concl]) and pandas.notna(hb_results_table_line[control_test_oe_desc]):\n",
    "                    # Getting the relevant control test (de+oe) for update/patch\n",
    "                    try:\n",
    "                        control_test_de_get_response = requests.request(\"GET\", hb_org_base_url + \"/walkthroughs/\" + control_test_de_id, headers=hb_request_headers)\n",
    "                        control_test_de_get_response.raise_for_status()\n",
    "                        control_test_oe_get_response = requests.request(\"GET\", hb_org_base_url + \"/control_tests/\" + control_test_oe_id, headers=hb_request_headers)\n",
    "                        control_test_oe_get_response.raise_for_status()\n",
    "                        if debug:\n",
    "                            print(\"GET DE response: \", control_test_de_get_response, \"\\n\")\n",
    "                            print(\"GET OE response: \", control_test_oe_get_response, \"\\n\")\n",
    "                    except requests.exceptions.RequestException as control_test_de_oe_get_err:\n",
    "                        raise requests.exceptions.RequestException(control_test_de_oe_get_err)\n",
    "                    # Grab the response as a JSON\n",
    "                    control_test_de_get_response_json = control_test_de_get_response.json()\n",
    "                    control_test_oe_get_response_json = control_test_oe_get_response.json()\n",
    "                    if debug:\n",
    "                        print(\"Before state of control de test:\\n\", control_test_de_get_response_json)\n",
    "                        print(\"Before state of control oe test:\\n\", control_test_oe_get_response_json)\n",
    "                    # Patch payload for control de+oe test update \n",
    "                    control_test_de_get_response_json[\"data\"][\"attributes\"][\"control_design\"] = True if hb_results_table_line[control_test_de_concl] == control_test_de_concl_t else False if hb_results_table_line[control_test_de_concl] == control_test_de_concl_f else None\n",
    "                    control_test_de_get_response_json[\"data\"][\"attributes\"][\"walkthrough_results\"] = hb_results_table_line[control_test_de_desc]\n",
    "                    control_test_oe_get_response_json[\"data\"][\"attributes\"][\"testing_conclusion\"] = True if hb_results_table_line[control_test_oe_concl] == control_test_oe_concl_t else False if hb_results_table_line[control_test_oe_concl] == control_test_oe_concl_f else None\n",
    "                    control_test_oe_get_response_json[\"data\"][\"attributes\"][\"testing_results\"] = hb_results_table_line[control_test_oe_desc]\n",
    "                    if debug:\n",
    "                        print(\"After state of control de test:\\n\", control_test_de_get_response_json)\n",
    "                        print(\"After state of control oe test:\\n\", control_test_oe_get_response_json)\n",
    "\n",
    "                    # Patching/updating the relevant control de+oe test\n",
    "                    try:\n",
    "                        control_test_de_patch_response = requests.request(\"PATCH\", hb_org_base_url + \"/walkthroughs/\" + control_test_de_id, data=json.dumps(control_test_de_get_response_json), headers=hb_request_headers)\n",
    "                        control_test_de_patch_response.raise_for_status()\n",
    "                        control_test_oe_patch_response = requests.request(\"PATCH\", hb_org_base_url + \"/control_tests/\" + control_test_oe_id, data=json.dumps(control_test_oe_get_response_json), headers=hb_request_headers)\n",
    "                        control_test_oe_patch_response.raise_for_status()\n",
    "                    except requests.exceptions.RequestException as control_test_de_oe_patch_err:\n",
    "                        raise requests.exceptions.RequestException(control_test_de_oe_patch_err)\n",
    "                    if debug:\n",
    "                        print(\"PATCH DE response: \", control_test_de_patch_response, \"\\n\")\n",
    "                        print(\"PATCH OE response: \", control_test_oe_patch_response, \"\\n\")\n",
    "                    \n",
    "                    record_counter += 1\n",
    "                    print(\"\\nGET RELEVANT CONTROL DE+OE RECORDS AND UPDATE THEIR DE+OE TESTING RESULTS TASK SUCCESSFULLY RAN FOR \" + str(hb_results_table_line.loc[\"Object ID\"]), \"\\n\\n\")\n",
    "\n",
    "\n",
    "                # **** CONTROL DE ONLY ****\n",
    "                elif pandas.notna(hb_results_table_line[control_test_de_concl]) and pandas.notna(hb_results_table_line[control_test_de_desc]):\n",
    "                    # Getting the relevant control test (de) for update/patch\n",
    "                    try:\n",
    "                        control_test_de_get_response = requests.request(\"GET\", hb_org_base_url + \"/walkthroughs/\" + control_test_de_id, headers=hb_request_headers)\n",
    "                        control_test_de_get_response.raise_for_status()\n",
    "                        if debug:\n",
    "                            print(\"GET response: \", control_test_de_get_response, \"\\n\")\n",
    "                    except requests.exceptions.RequestException as control_test_de_get_err:\n",
    "                        raise requests.exceptions.RequestException(control_test_de_get_err)\n",
    "                    # Grab the response as a JSON\n",
    "                    control_test_de_get_response_json = control_test_de_get_response.json()\n",
    "                    if debug:\n",
    "                        print(\"Before state of control de test:\\n\", control_test_de_get_response_json)\n",
    "                    # Patch payload for control de test update \n",
    "                    control_test_de_get_response_json[\"data\"][\"attributes\"][\"control_design\"] = True if hb_results_table_line[control_test_de_concl] == control_test_de_concl_t else False if hb_results_table_line[control_test_de_concl] == control_test_de_concl_f else None\n",
    "                    control_test_de_get_response_json[\"data\"][\"attributes\"][\"walkthrough_results\"] = hb_results_table_line[control_test_de_desc]\n",
    "                    if debug:\n",
    "                        print(\"After state of control de test:\\n\", control_test_de_get_response_json)\n",
    "\n",
    "                    # Patching/updating the relevant control de test\n",
    "                    try:\n",
    "                        control_test_de_patch_response = requests.request(\"PATCH\", hb_org_base_url + \"/walkthroughs/\" + control_test_de_id, data=json.dumps(control_test_de_get_response_json), headers=hb_request_headers)\n",
    "                        control_test_de_patch_response.raise_for_status()\n",
    "                    except requests.exceptions.RequestException as control_test_de_patch_err:\n",
    "                        raise requests.exceptions.RequestException(control_test_de_patch_err)\n",
    "                    if debug:\n",
    "                        print(\"PATCH response: \", control_test_de_patch_response, \"\\n\")\n",
    "                    \n",
    "                    record_counter += 1\n",
    "                    print(\"\\nGET RELEVANT CONTROL DE RECORDS AND UPDATE THEIR DE TESTING RESULTS TASK SUCCESSFULLY RAN FOR \" + str(hb_results_table_line.loc[\"Object ID\"]), \"\\n\\n\")\n",
    "\n",
    "\n",
    "                # **** CONTROL OE ONLY ****\n",
    "                elif pandas.notna(hb_results_table_line[control_test_oe_concl]) and pandas.notna(hb_results_table_line[control_test_oe_desc]):\n",
    "                    # Getting the relevant control test (oe) for update/patch\n",
    "                    try:\n",
    "                        control_test_oe_get_response = requests.request(\"GET\", hb_org_base_url + \"/control_tests/\" + control_test_oe_id, headers=hb_request_headers)\n",
    "                        control_test_oe_get_response.raise_for_status()\n",
    "                        if debug:\n",
    "                            print(\"GET response: \", control_test_oe_get_response, \"\\n\")\n",
    "                    except requests.exceptions.RequestException as control_test_oe_get_err:\n",
    "                        raise requests.exceptions.RequestException(control_test_oe_get_err)\n",
    "                    # Grab the response as a JSON\n",
    "                    control_test_oe_get_response_json = control_test_oe_get_response.json()\n",
    "                    if debug:\n",
    "                        print(\"Before state of control oe test:\\n\", control_test_oe_get_response_json)\n",
    "                    # Patch payload for control oe test update \n",
    "                    control_test_oe_get_response_json[\"data\"][\"attributes\"][\"testing_conclusion\"] = True if hb_results_table_line[control_test_oe_concl] == control_test_oe_concl_t else False if hb_results_table_line[control_test_oe_concl] == control_test_oe_concl_f else None\n",
    "                    control_test_oe_get_response_json[\"data\"][\"attributes\"][\"testing_results\"] = hb_results_table_line[control_test_oe_desc]\n",
    "                    if debug:\n",
    "                        print(\"After state of control oe test:\\n\", control_test_oe_get_response_json)\n",
    "\n",
    "                    # Patching/updating the relevant control oe test\n",
    "                    try:\n",
    "                        control_test_oe_patch_response = requests.request(\"PATCH\", hb_org_base_url + \"/control_tests/\" + control_test_oe_id, data=json.dumps(control_test_oe_get_response_json), headers=hb_request_headers)\n",
    "                        control_test_oe_patch_response.raise_for_status()\n",
    "                    except requests.exceptions.RequestException as control_test_oe_patch_err:\n",
    "                        raise requests.exceptions.RequestException(control_test_oe_patch_err)\n",
    "                    if debug:\n",
    "                        print(\"PATCH response: \", control_test_oe_patch_response, \"\\n\")\n",
    "                    \n",
    "                    record_counter += 1\n",
    "                    print(\"\\nGET RELEVANT CONTROL OE RECORDS AND UPDATE THEIR OE TESTING RESULTS TASK SUCCESSFULLY RAN FOR \" + str(hb_results_table_line.loc[\"Object ID\"]), \"\\n\\n\")\n",
    "\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    \n",
    "        print(f\"\\n>>>>>>>>>> PROCESSING RESULTS TABLE RECORDS TASK COMPLETED FOR \" + str(hb_results_table.loc[\"id_table\"]) + \"! \" + str(record_counter) + \" record(s) processed. <<<<<<<<<<\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n\\nROBOT TASK RUN COMPLETED SUCCESSFULLY!\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
