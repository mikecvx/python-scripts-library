{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENVIRONMENT SETTINGS\n",
    "import requests, pandas, numpy\n",
    "\n",
    "pandas.options.display.max_rows = 10\n",
    "pandas.options.display.max_columns = None\n",
    "pandas.options.display.max_colwidth = 50\n",
    "\n",
    "\"\"\"\n",
    "# Checking user input variables. If they're not provided, raise exception and terminate script.\n",
    "if len(hcl.secret[\"v_hb_token\"].unmask()) == 0:\n",
    "    raise KeyError(\"HighBond token not provided.\")\n",
    "if len(hcl.variable[\"v_hb_results_table_id\"].strip()) == 0:\n",
    "    raise KeyError(\"Highbond Results Table ID not provided.\")\n",
    "else:\n",
    "    V_RESULTS_TABLE_ID: str = hcl.variable[\"v_hb_results_table_id\"].strip()\n",
    "if len(hcl.variable[\"v_hb_project_id\"].strip()) == 0:\n",
    "    raise KeyError(\"Highbond Project ID not provided.\")\n",
    "else:\n",
    "    V_PROJECT_ID: str = hcl.variable[\"v_hb_project_id\"].strip()\n",
    "\"\"\"\n",
    "\n",
    "# Set the variables\n",
    "V_ORG_ID: str = \"30664\"\n",
    "\n",
    "# Highbond url\n",
    "org_base_url: str = \"https://apis-eu.highbond.com/v1/orgs/\" + V_ORG_ID.strip()\n",
    "    \n",
    "# Request headers for Highbond\n",
    "highbond_request_headers: dict = {\n",
    "    \"Authorization\": \"Bearer ee93272f8f8e718d9e7ad027f2f13e0eb345c938709d9ac759821b152ee709cc\",\n",
    "#    \"Authorization\": \"Bearer {}\".format(hcl.secret[\"v_hb_token\"].unmask()),\n",
    "    \"Content-Type\": \"application/vnd.api+json\",\n",
    "    \"Accept-encoding\": \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE HELPER FUNCTIONS\n",
    "\n",
    "# Function 1 - Helper function to handle pagination and grab all Highbond resources\n",
    "def highbond_api_get_all(resource_url_body: str) -> list:\n",
    "    \"\"\"\n",
    "    Importing Highbond data and creating a list\n",
    "    Args:\n",
    "        resource_url_body: URL body of the request\n",
    "    Returns:\n",
    "        List of resources\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = requests.request(\"GET\", org_base_url + resource_url_body, headers=highbond_request_headers)\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        raise requests.exceptions.RequestException(err)\n",
    "    \n",
    "    response_json = response.json()\n",
    "    list_of_result_dicts = response_json[\"data\"]\n",
    "    while response.status_code == 200:\n",
    "        if response_json['links']['next'] and len(response_json['links']['next']) > 0:\n",
    "            next_url = response_json['links']['next']\n",
    "            \n",
    "            try:\n",
    "                response = requests.request(\"GET\", org_base_url + next_url, headers=highbond_request_headers)\n",
    "                response.raise_for_status()\n",
    "            except requests.exceptions.RequestException as err:\n",
    "                raise requests.exceptions.RequestException(err)\n",
    "        \n",
    "            response_json = response.json()\n",
    "            list_of_result_dicts.extend(response_json[\"data\"])\n",
    "        \n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return list_of_result_dicts\n",
    "\n",
    "\n",
    "##################################################################\n",
    "# Function 2 - Helper function to flatten all custom attributes\n",
    "def flatten_custom_attributes(custom_attribute_field_value):\n",
    "    \"\"\"\n",
    "    Flattening the custom attributes in the dataframe\n",
    "    Args:\n",
    "        custom_attribute_field_value: custom attributes\n",
    "    Returns:\n",
    "        Dictionary with flattened custom attributes \n",
    "    \"\"\"\n",
    "\n",
    "    custom_attribute_dict = {} # Initialize empty dictionary\n",
    "    for attribute in custom_attribute_field_value:           # There can be multiple custom attributes, so we need to loop through each one to parse it\n",
    "        if isinstance(attribute[\"value\"], list) and len(attribute[\"value\"]) == 1:   # If the custom attribute value is a list itself and only having one value, \"de-listify it\"\n",
    "            attribute[\"value\"] = attribute[\"value\"][0] # De listifies the value list\n",
    "        elif isinstance(attribute[\"value\"], list) and not attribute[\"value\"]:\n",
    "            attribute[\"value\"] = None # De listifies the value list\n",
    "        custom_attribute_dict[attribute[\"term\"]] = attribute[\"value\"] # Create the dictionary tuple with the custom attribute term and value\n",
    "    return custom_attribute_dict # Return the completed dictionary\n",
    "\n",
    "\n",
    "##################################################################\n",
    "# Function 3 - GET Results Tables Data\n",
    "def get_from_hb_results(results_table_id: str, include_metadata: bool = False, display_names: bool = False) -> pandas.DataFrame:\n",
    "    \"\"\"\n",
    "    Importing current Results Table in a formatted way\n",
    "    Args:\n",
    "        results_table_id: ID of the Highbond Results Table\n",
    "        include_metadata: Include metadata fields in the import or not\n",
    "        display_names: Use display name or technical name of Results Table fields\n",
    "    Returns:\n",
    "        Current Results table in a pandas dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # Submit the request and grab the response, and convert it to JSON\n",
    "    # Note that the hb_api methods handle authentication and org_id\n",
    "    try:\n",
    "        request_endpoint = \"/tables/\" + results_table_id + \"/records/\"\n",
    "        request_response = requests.request(\"GET\", org_base_url + request_endpoint, headers=highbond_request_headers)\n",
    "        request_response.raise_for_status()\n",
    "        print(\"Get assets response: \", request_response, \"\\n\")\n",
    "\n",
    "        # If the response isn't successful, raise it as an error. Probably because the API key is incorrect.\n",
    "        if request_response.status_code != 200:\n",
    "            raise ConnectionError(\"Could not connect to HighBond (\"+request_endpoint+\"). Check the HighBond token value: v_hb_token\")\n",
    "        \n",
    "    except requests.exceptions.RequestException as get_err:\n",
    "        raise requests.exceptions.RequestException(get_err)\n",
    "\n",
    "    # Grab the response as a JSON\n",
    "    request_json = request_response.json()\n",
    "    Results_Records_df = pandas.DataFrame(request_json[\"data\"])        # Convert the response JSON to a dataframe -- we grab data from the \"data\" element\n",
    "\n",
    "    print(\"Before: \" + Results_Records_df.columns)    \n",
    "\n",
    "    if not include_metadata:\n",
    "        for column_name in Results_Records_df.columns:\n",
    "            if column_name.startswith('metadata.') or column_name.startswith('extras.'): \n",
    "                del Results_Records_df[column_name]\n",
    "\n",
    "    print(\"After: \" + Results_Records_df.columns)    \n",
    "\n",
    "    # Grab the columns metadata into a dataframe\n",
    "    Results_Columns_df = pandas.DataFrame(request_json[\"columns\"])\n",
    "\n",
    "    # Create a dictionary from the display name and field name\n",
    "    Results_Column_Mapping_dict = pandas.Series(Results_Columns_df.display_name.values,index=Results_Columns_df.field_name).to_dict()\n",
    "\n",
    "    if display_names:\n",
    "        # Grab the records from the response and rename the columns\n",
    "        Results_Records_df.rename(columns = Results_Column_Mapping_dict, inplace = True)\n",
    "        Results_Records_df = Results_Records_df.convert_dtypes()\n",
    "\n",
    "    return Results_Records_df\n",
    "\n",
    "\n",
    "##################################################################\n",
    "# Function 4 - Export dataframe to Results\n",
    "def post_to_hb_results(results_dataframe: pandas.DataFrame, results_table_id: str) -> None:\n",
    "    \"\"\"\n",
    "    Exporting DataFrame to a Results Table\n",
    "    Args:\n",
    "        results_dataframe: pandas dataframe of the data to be export to Results Table\n",
    "        results_table_id: ID of the Highbond Results Table\n",
    "    Returns:\n",
    "        Nothing\n",
    "    \"\"\"\n",
    "\n",
    "    results_df_hcl_df = hcl.from_pandas(results_dataframe)\n",
    "    results_df_hcl_df.to_hb_results(table_id = results_table_id, overwrite = False)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN LOGIC 1\n",
    "#Update Highbond Projects Data in Results Table\n",
    "\n",
    "# Grab list of all objectives and filter them for the relevant project\n",
    "objectives_fields = \"title,reference\"\n",
    "objectives_list = highbond_api_get_all(\"/projects/\" + V_PROJECT_ID.strip() + \"/objectives?fields[objectives]=\" + objectives_fields)\n",
    "\n",
    "# Create Objectives Dataframe\n",
    "objectives_df = pandas.json_normalize(objectives_list)\n",
    "objectives_df\n",
    "\n",
    "\n",
    "\n",
    "# Grab list of all risks and filter them for the relevant objectives\n",
    "risks_fields = \"risk_id,title,custom_attributes,objective\"\n",
    "risks_list = []\n",
    "for objective in objectives_list:\n",
    "    risks_list_current = highbond_api_get_all(\"/objectives/\" + objective[\"id\"] + \"/risks?fields[risks]=\" + risks_fields)\n",
    "    risks_list.extend(risks_list_current)\n",
    "    \n",
    "# Create Risks Dataframe\n",
    "risks_df = pandas.json_normalize(risks_list)\n",
    "risks_df\n",
    "\n",
    "# If custom attributes exist, then convert them to columns in the dataframe\n",
    "if \"attributes.custom_attributes\" in risks_df.columns: \n",
    "    custom_attribute_df = pandas.json_normalize(risks_df[\"attributes.custom_attributes\"].apply(flatten_custom_attributes)) # Convert the custom attributes into a dataframe using the above function\n",
    "    risks_df = risks_df.join(custom_attribute_df) # Join the custom attribute dataframe to our risks dataframe\n",
    "\n",
    "# Merging Objectives and Risks dataframes\n",
    "risks_objectives_df = pandas.merge(risks_df, objectives_df, left_on=\"relationships.objective.data.id\", right_on=\"id\", suffixes=('___x_risks','___y_objectives'))\n",
    "risks_objectives_df\n",
    "\n",
    "# Renaming and removing unused fields\n",
    "risks_objectives_df[\"Sourcebook\"] = risks_objectives_df[\"attributes.title___y_objectives\"]\n",
    "risks_objectives_df[\"Activity unique ID\"] = risks_objectives_df[\"id___x_risks\"]\n",
    "risks_objectives_df[\"Activity reference\"] = risks_objectives_df[\"attributes.reference\"] + risks_objectives_df[\"attributes.risk_id\"]\n",
    "risks_objectives_df[\"Activity\"] = risks_objectives_df[\"attributes.title___x_risks\"]\n",
    "risks_objectives_df[\"Sourcebook\"] = risks_objectives_df[\"attributes.title___y_objectives\"]\n",
    "\n",
    "risks_objectives_df = risks_objectives_df[[\"Sourcebook\", \"Activity unique ID\", \"Activity reference\", \"Activity\", \"Compliance owner\", \"Initial review date\", \"Revised review date (if applicable)\"]]\n",
    "risks_objectives_df\n",
    "\n",
    "\n",
    "\n",
    "# Exporting final dataframe to Results\n",
    "post_to_hb_results(risks_objectives_df, V_RESULTS_TABLE_ID)\n",
    "print(\"Projects data export successful to Results Table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN LOGIC 2\n",
    "#Update Results Table with table calculations\n",
    "\n",
    "# Getting current data from Results\n",
    "results_df = get_from_hb_results(V_RESULTS_TABLE_ID)\n",
    "results_df\n",
    "\n",
    "# Replacing blank values with 0s for calculated fields\n",
    "results_df[\"q1018484_new\"] = results_df['q1018484'].fillna(\"0\")\n",
    "results_df[\"q1018485_new\"] = results_df['q1018485'].fillna(\"0\")\n",
    "results_df[\"q1018486_new\"] = results_df['q1018486'].fillna(\"0\")\n",
    "results_df[\"q1018487_new\"] = results_df['q1018487'].fillna(\"0\")\n",
    "results_df[\"q1018488_new\"] = results_df['q1018488'].fillna(\"0\")\n",
    "results_df[\"q1018489_new\"] = results_df['q1018489'].fillna(\"0\")\n",
    "results_df[\"q1018490_new\"] = results_df['q1018490'].fillna(\"0\")\n",
    "results_df[\"q1018491_new\"] = results_df['q1018491'].fillna(\"0\")\n",
    "results_df[\"q1018492_new\"] = results_df['q1018492'].fillna(\"0\")\n",
    "results_df[\"q1018493_new\"] = results_df['q1018493'].fillna(\"0\")\n",
    "results_df[\"q1018494_new\"] = results_df['q1018494'].fillna(\"0\")\n",
    "results_df\n",
    "\n",
    "# Calculating Total Risk Score\n",
    "results_df[\"Total Risk Score\"] = results_df.apply(lambda x: sum([int(x[\"q1018484_new\"].split(\"-\")[0]),int(x[\"q1018485_new\"].split(\"-\")[0]),int(x[\"q1018486_new\"].split(\"-\")[0]),int(x[\"q1018487_new\"].split(\"-\")[0]),int(x[\"q1018488_new\"].split(\"-\")[0]),int(x[\"q1018489_new\"].split(\"-\")[0]),int(x[\"q1018490_new\"].split(\"-\")[0]),int(x[\"q1018491_new\"].split(\"-\")[0]),int(x[\"q1018492_new\"].split(\"-\")[0]),int(x[\"q1018493_new\"].split(\"-\")[0]),int(x[\"q1018494_new\"].split(\"-\")[0])]), axis=1)\n",
    "results_df\n",
    "\n",
    "# Calculating Risk Category\n",
    "conditions = [\n",
    "    (results_df[\"Total Risk Score\"] ==  0),\n",
    "    (results_df[\"Total Risk Score\"] >   0) & (results_df[\"Total Risk Score\"] <= 12),\n",
    "    (results_df[\"Total Risk Score\"] >  10) & (results_df[\"Total Risk Score\"] <= 22),\n",
    "    (results_df[\"Total Risk Score\"] >  22)]\n",
    "choices = [None,'Low Risk', 'Medium Risk', 'High Risk']\n",
    "results_df['Risk Category'] = numpy.select(conditions, choices)\n",
    "results_df\n",
    "\n",
    "# Calculating Next Assessment Date\n",
    "results_df[\"Initial review date\"] = pandas.to_datetime(results_df[\"Initial review date\"])\n",
    "results_df[\"Revised review date (if applicable)\"] = pandas.to_datetime(results_df[\"Revised review date (if applicable)\"])\n",
    "results_df[\"Next Review Date\"] = results_df.apply(lambda x: x[\"Revised review date (if applicable)\"].to_period(\"Q\") if not pandas.isna(x[\"Revised review date (if applicable)\"]) else (x[\"Initial review date\"] + pandas.DateOffset(months=12)).to_period(\"Q\") if not pandas.isna(x[\"Initial review date\"]) and x[\"Risk Category\"] == \"High Risk\" else (x[\"Initial review date\"] + pandas.DateOffset(months=18)).to_period(\"Q\") if not pandas.isna(x[\"Initial review date\"]) and x[\"Risk Category\"] == \"Medium Risk\" else (x[\"Initial review date\"] + pandas.DateOffset(months=24)).to_period(\"Q\") if not pandas.isna(x[\"Initial review date\"]) and x[\"Risk Category\"] == \"Low Risk\" else None, axis=1)\n",
    "\n",
    "# Scoping the export fields\n",
    "results_df = results_df[[\"Sourcebook\", \"Activity unique ID\", \"Activity reference\", \"Activity\", \"Compliance owner\", \"Initial review date\", \"Revised review date (if applicable)\", \"q1018484\",\"q1018485\",\"q1018486\",\"q1018487\",\"q1018488\",\"q1018489\",\"q1018490\",\"q1018491\",\"q1018492\",\"q1018493\",\"q1018484\",\"Total Risk Score\",\"Risk Category\",\"Next Review Date\"]]\n",
    "results_df\n",
    "\n",
    "\n",
    "\n",
    "# Exporting final dataframe to Results\n",
    "post_to_hb_results(results_df, V_RESULTS_TABLE_ID)\n",
    "print(\"Results table calculation data export successful to Results Table\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
